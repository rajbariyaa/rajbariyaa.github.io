---
layout: post
title: "Day 30 - Hyperparameter Tuning"
date: 2025-07-07
author: Raj Bariya
permalink: /day30.html
tags: ["Hyperparameter"]

what_i_learned: |
 Today, after arriving at the lab, our team gathered together, and Abiola gave us a detailed review of our presentation. Her feedback was constructive and helped us reflect on both the strengths and areas for improvement. Following the review, she divided the tasks among the team members to keep us organized and on track. I was assigned the task of improving the accuracy of our machine learning model. Currently, the model achieves an accuracy of 89%, but my goal is to push it above 93%. To reach this target, I decided to take a two-pronged approach: hyperparameter tuning and experimenting with a hybrid model. Today, I focused on the first approach, hyperparameter tuning. I spent some time researching best practices and understanding how different parameters influence the model's performance. After gaining a clearer picture, I wrote the code to implement the tuning. However, due to the computational intensity, my laptop wasn’t able to handle the processing. Thankfully, my teammate Brice offered to run the code on his computer, which was better equipped for the task. Overall, it was a good day of learning and collaboration, and I’m excited to see how these strategies improve our model’s performance in the coming days.
blockers: |
  The only blocker I had is that my computer is not able to run the code and we will see if any error occurs after running the code.
reflection: |
  Today was a productive and enjoyable day at the lab. We received feedback on our presentation, which helped us better understand the areas we did well in and where we could improve. After the review session, we took some time to divide tasks among our team members, making sure everyone had a clear role moving forward. One of the highlights for me was working with hyperparameter tuning. Although I had learned about it a few weeks ago, this was my first time actually implementing it in a real-world project. It was exciting to see how small adjustments in model parameters could significantly improve performance, and I’m beginning to appreciate the trial-and-error nature of fine-tuning machine learning models. Overall, everything seems to be progressing smoothly, and the team is aligned on our goals. If things continue at this pace, we’re optimistic about having our dashboard up and running by the end of the week. I’m looking forward to seeing how everything comes together!
---
